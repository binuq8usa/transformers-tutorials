{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration of self -attention for connected graphs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Node : [[ 0.4626994 ]\n",
      " [ 4.75630941]\n",
      " [-3.40442323]\n",
      " [-0.24714526]\n",
      " [ 0.82205102]\n",
      " [ 1.20897123]\n",
      " [ 1.39797928]\n",
      " [ 1.66658014]]\n",
      "query Node : [[-1.15038849]\n",
      " [-1.29709697]\n",
      " [ 0.98150268]\n",
      " [ 4.72505494]\n",
      " [ 2.47338327]\n",
      " [ 1.50709356]\n",
      " [-0.80299357]\n",
      " [-1.70404016]]\n",
      "value Node : [[ 0.60668619]\n",
      " [ 3.28401293]\n",
      " [-1.58843323]\n",
      " [ 0.00711878]\n",
      " [-0.78993758]\n",
      " [-1.35890831]\n",
      " [ 5.30046708]\n",
      " [ 1.71565161]]\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, id, embed_size) -> None:\n",
    "        self.embed_size = embed_size\n",
    "        # define the Weigths for keys, value, and query\n",
    "        self.weights_key = np.random.randn(embed_size, embed_size)\n",
    "        self.weights_query = np.random.randn(embed_size, embed_size)\n",
    "        self.weights_value = np.random.randn(embed_size, embed_size)\n",
    "        self.id = id\n",
    "        self.data = np.random.randn(embed_size, 1)\n",
    "    \n",
    "    def get_key(self) -> np.array:\n",
    "        return self.weights_key @ self.data\n",
    "    \n",
    "    def get_query(self) -> np.array:\n",
    "        return self.weights_query @ self.data\n",
    "\n",
    "    def get_value(self) -> np.array:\n",
    "        return self.weights_value @ self.data\n",
    "\n",
    "embed_size=8\n",
    "data = np.random.randn(embed_size,1)\n",
    "node : Node = Node(id=1, embed_size=embed_size)\n",
    "\n",
    "print(f'Key Node : {node.get_key()}')\n",
    "print(f'query Node : {node.get_query()}')\n",
    "print(f'value Node : {node.get_value()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node : [[ 1.87004213]\n",
      " [ 2.95803927]\n",
      " [ 0.45843419]\n",
      " [-1.08161022]\n",
      " [ 1.20145844]\n",
      " [ 2.62779471]\n",
      " [ 4.02582803]\n",
      " [-2.40531459]]\n"
     ]
    }
   ],
   "source": [
    "# define the graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 -> [1, 5]\n",
      "Node 1 -> [2, 4]\n",
      "Node 2 -> [3]\n",
      "Node 3 -> [0, 1]\n",
      "Node 4 -> [3]\n",
      "Node 5 -> [4]\n",
      "Node 0 <- [3]\n",
      "Node 1 <- [0, 3]\n",
      "Node 2 <- [1]\n",
      "Node 3 <- [2, 4]\n",
      "Node 4 <- [1, 5]\n",
      "Node 5 <- [0]\n",
      "Scores for Node 0 : [[[1.]]]\n",
      "Update for Node 0 : [[-0.1369384 ]\n",
      " [ 0.21513234]\n",
      " [-0.63818914]\n",
      " [ 0.87274661]\n",
      " [-3.58753591]\n",
      " [-0.2935847 ]\n",
      " [ 0.50978782]\n",
      " [ 2.90907945]]\n",
      "Scores for Node 1 : [[[0.02323996]]\n",
      "\n",
      " [[0.97676004]]]\n",
      "Update for Node 1 : [[-0.22575942]\n",
      " [ 0.24152754]\n",
      " [-0.66833969]\n",
      " [ 0.78985401]\n",
      " [-3.52546204]\n",
      " [-0.35101307]\n",
      " [ 0.58211253]\n",
      " [ 2.8256734 ]]\n",
      "Scores for Node 2 : [[[1.]]]\n",
      "Update for Node 2 : [[-1.67320754]\n",
      " [-0.37502434]\n",
      " [ 0.43805411]\n",
      " [ 1.86356745]\n",
      " [ 0.77415342]\n",
      " [-0.28624065]\n",
      " [-4.72286251]\n",
      " [-1.21263537]]\n",
      "Scores for Node 3 : [[[0.99359623]]\n",
      "\n",
      " [[0.00640377]]]\n",
      "Update for Node 3 : [[ 2.46450992]\n",
      " [ 1.60815185]\n",
      " [ 1.15011059]\n",
      " [-4.38669085]\n",
      " [ 4.71130729]\n",
      " [-2.53225295]\n",
      " [-3.90145627]\n",
      " [ 5.91356638]]\n",
      "Scores for Node 4 : [[[5.85335271e-23]]\n",
      "\n",
      " [[1.00000000e+00]]]\n",
      "Update for Node 4 : [[-3.24066575]\n",
      " [-0.6842716 ]\n",
      " [ 2.19779522]\n",
      " [-0.95875784]\n",
      " [ 0.41771768]\n",
      " [-3.27274531]\n",
      " [ 2.77651719]\n",
      " [ 9.22660298]]\n",
      "Scores for Node 5 : [[[1.]]]\n",
      "Update for Node 5 : [[-3.95884827]\n",
      " [ 1.35090044]\n",
      " [-1.93554726]\n",
      " [-2.69406725]\n",
      " [-0.91653833]\n",
      " [-2.76468942]\n",
      " [ 3.62187221]\n",
      " [-0.67982784]]\n"
     ]
    }
   ],
   "source": [
    "# Graph\n",
    "from typing import List, Dict, OrderedDict\n",
    "from collections import OrderedDict\n",
    "class Graph:\n",
    "    def __init__(self, embed_size) -> None:\n",
    "        self.nodes : OrderedDict[int, Node] = OrderedDict()\n",
    "        self.out_edges : OrderedDict[int, List[int]] = OrderedDict() # Node id -> neighbhors in forward pass\n",
    "        self.in_edges : OrderedDict[int, List[int]] = OrderedDict()\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "    def read_graph(self,txt_file):\n",
    "        with open(txt_file, 'r') as fid:\n",
    "            data = fid.readlines()\n",
    "            data = [list(map(int,d.rstrip().split(','))) for d in data]   \n",
    "            ids = np.unique([d[0] for d in data] )\n",
    "            for id in ids:\n",
    "                self.nodes[id] = Node(id,self.embed_size)\n",
    "                \n",
    "            # read the edges\n",
    "            for d in data:\n",
    "                # create the outgooing edge map\n",
    "                if d[0] in self.out_edges:\n",
    "                    self.out_edges[d[0]].append(d[1])\n",
    "                    self.out_edges[d[0]].sort()\n",
    "                else:\n",
    "                    self.out_edges[d[0]] = [d[1]]\n",
    "                    \n",
    "                # create the incoming edge map\n",
    "                if d[1] in self.in_edges:\n",
    "                    self.in_edges[d[1]].append(d[0])\n",
    "                    self.in_edges[d[1]].sort()\n",
    "                else:\n",
    "                    self.in_edges[d[1]] = [d[0]] \n",
    "                    \n",
    "                    \n",
    "    def print_graph(self):\n",
    "        for idx,node in self.nodes.items():\n",
    "            list_of_out_edges = self.out_edges[node.id]\n",
    "            print(f'Node {node.id} -> {list_of_out_edges}')\n",
    "           \n",
    "        for idx, node in self.nodes.items(): \n",
    "            list_of_in_edges = self.in_edges[node.id]\n",
    "            print(f'Node {node.id} <- {list_of_in_edges}')\n",
    "    \n",
    "    def compute_attention(self):\n",
    "        updates = []\n",
    "        for idx, node in self.nodes.items():\n",
    "            # compute the query\n",
    "            query_vec = node.get_query()\n",
    "            \n",
    "            # get the keys from the incoming edges - 2 keys\n",
    "            key_vec_list = [self.nodes[idx].get_key() for idx in self.in_edges[node.id]]\n",
    "            \n",
    "            # compute the scores - 2 scores - \n",
    "            scores = [key_vec.T.dot(query_vec) for key_vec in key_vec_list]\n",
    "            scores = np.exp(np.array(scores))\n",
    "            scores /= np.sum(scores)\n",
    "            print(f'Scores for Node {idx} : {scores}')\n",
    "            \n",
    "            # compute the values from the incoming edges -  2 value vec each with D dimension\n",
    "            value_vec_list = np.array([self.nodes[idx].get_value() for idx in self.in_edges[node.id]])\n",
    "            value_vec_list = np.array(value_vec_list)\n",
    "            \n",
    "            # compute the updates\n",
    "            # scores = scores.squeeze()\n",
    "            # value_vec_list = value_vec_list.squeeze()\n",
    "            # if scores.ndim == 0:\n",
    "            #     update = scores * value_vec_list\n",
    "            # else:\n",
    "            #     update = np.sum(scores[:,np.newaxis] * value_vec_list, axis=0)\n",
    "            update = np.sum(scores * value_vec_list, axis=0)\n",
    "            print(f'Update for Node {idx} : {update}')\n",
    "            updates.append(update)\n",
    "        \n",
    "        # do update\n",
    "        for idx, update in zip(self.nodes.keys(), updates):\n",
    "            self.nodes[idx].data += update\n",
    "            \n",
    "\n",
    "embed_size = 8\n",
    "txt_file = \"sample_graph.txt\"\n",
    "net : Graph = Graph(embed_size=embed_size)\n",
    "net.read_graph(txt_file)    \n",
    "net.print_graph()\n",
    "net.compute_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute self attendrion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
